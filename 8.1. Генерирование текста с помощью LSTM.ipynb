{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8.1. Генерирование текста с помощью LSTM.ipynb","provenance":[],"authorship_tag":"ABX9TyP/qT9WpOgzsXIOZJi8b/bF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6fnM_WwyD8sP"},"source":["## 8.1.3. Важность стратегии выбора\n","\n","Для управления величиной случайности в процессе выбора введем параметр,\n","который назовем температурой softmax, характеризующий энтропию распределения вероятностей, используемую для выбора: она будет определять степень необычности или предсказуемости выбора следующего символа. С учетом значения\n","temperature и на основе оригинального распределения вероятностей (результата\n","функции softmax модели) будет вычисляться новое распределение путем взвешивания вероятностей, как показано ниже."]},{"cell_type":"code","metadata":{"id":"DbqBqN5VED-A","executionInfo":{"status":"ok","timestamp":1636105030038,"user_tz":-420,"elapsed":308,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}}},"source":["# Взвешивание распределения вероятностей с учетом значения температуры\n","\n","import numpy as np\n","\n","def reweight_distribution(original_distribution, temperature=0.5):  # original_distribution — это одномерный массив Numpy\n","                                                                      # значений вероятностей, сумма которых должна быть равна 1\n","\n","    distribution = np.log(original_distribution) / temperature\n","    distribution = np.exp(distribution)\n","    return distribution / np.sum(distribution)                      # Возвращает новую, взвешенную версию оригинального распределения. Сумма вероятностей\n","                                                                      # в новом распределении может получиться больше 1, поэтому разделим элементы вектора на сумму,\n","                                                                      # чтобы получить новое распределение\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-tm3Aa0FIBy"},"source":["## 8.1.4. Реализация посимвольной генерации текста на основе LSTM\n","\n","Воплотим эти идеи на практике в реализации с Keras. Первое, что нам понадобится, — это много текстовых данных, на которых можно было бы обучить языковую\n","модель. Для этого можно использовать любой большой текстовый файл или набор текстовых файлов, например статьи из Википедии, роман «Властелин колец»\n","и т. д. В данном примере мы используем тексты из произведений Ницше, немецкого\n","философа конца XIX века (в переводе на английский язык). Таким образом, в результате обучения у нас получится языковая модель, обладающая специфическими\n","особенностями, характерными для произведений Ницше, а не обобщенная модель\n","английского языка.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kst2XxLbFV_8","executionInfo":{"status":"ok","timestamp":1636105036975,"user_tz":-420,"elapsed":5040,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}},"outputId":"4faad678-7c46-4e8f-a380-15e91e7104fa"},"source":["# Загрузка и парсинг исходного текстового файла\n","\n","import tensorflow.keras.utils\n","import numpy as np\n","path = tensorflow.keras.utils.get_file(\n","        'nietzsche.txt',\n","        origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","text = open(path).read().lower()\n","print('Corpus length:', len(text))  "],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus length: 600893\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Euw1t3YTFuvS","executionInfo":{"status":"ok","timestamp":1636105044222,"user_tz":-420,"elapsed":4755,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}},"outputId":"6e8d6269-30c1-42c1-c5f6-93c3c7c7dc58"},"source":["# Векторизация последовательностей символов\n","\n","maxlen = 60                                                                     # Извлечение последовательностей по 60 символов\n","\n","step = 3                                                                        # Новые последовательности выбираются через каждые 3 символа\n","\n","sentences = []                                                                  # Хранение извлеченных последовательностей\n","\n","next_chars = []                                                                 # Хранение целей (символов, следующих за последовательностями)\n","\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('Number of sequences:', len(sentences))\n","\n","chars = sorted(list(set(text)))                                                 # Список уникальных символов в корпусе\n","print('Unique characters:', len(chars))\n","char_indices = dict((char, chars.index(char)) for char in chars)                # Словарь, отображающий уникальные символы в их\n","                                                                                  # индексы в списке «chars»\n","\n","print('Vectorization...')\n","\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1                                       # Прямое кодирование символов\n","                                                                                  # в бинарные массивы\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sequences: 200278\n","Unique characters: 57\n","Vectorization...\n"]}]},{"cell_type":"markdown","metadata":{"id":"34wYmam2Kp-i"},"source":["### Конструирование сети\n","\n","Эта сеть состоит из единственного слоя LSTM, за которым следует классификатор\n","Dense с функцией softmax выбора из всех возможных символов. Но имейте в виду,\n","что рекуррентные нейронные сети не единственный способ генерирования последовательностей данных; одномерные сверточные сети тоже показали превосходные\n","результаты в решении этой задачи."]},{"cell_type":"code","metadata":{"id":"Ej8VlcW3Kkk0","executionInfo":{"status":"ok","timestamp":1636105054140,"user_tz":-420,"elapsed":6528,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}}},"source":["# Модель с единственным слоем LSTM для предсказания следующего символа\n","\n","from keras import layers\n","\n","model = tensorflow.keras.models.Sequential()\n","model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n","model.add(layers.Dense(len(chars), activation='softmax'))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKztWqW9LCjT"},"source":["Так как цели имеют формат прямого кодирования, используем для обучения модели функцию потерь categorical_crossentropy."]},{"cell_type":"code","metadata":{"id":"4rPFBCj6K_pj","executionInfo":{"status":"ok","timestamp":1636105056746,"user_tz":-420,"elapsed":288,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}}},"source":["# Конфигурация компилируемой модели\n","\n","optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71dM_Aj3LTPW"},"source":["### Обучение модели и извлечение образцов из нее\n","\n","Имея обученную модель и фрагмент начального текста, можно сгенерировать новый текст, выполнив следующие пункты:\n","\n","1. Извлечь из модели распределение вероятностей следующего символа для имеющегося на данный момент сгенерированного текста.\n","\n","2. Выполнить взвешивание распределения с заданной температурой.\n","\n","3. Выбрать следующий символ в соответствии с вновь взвешенным распределением вероятностей.\n","\n","4. Добавить новый символ в конец текста.\n","\n","Вот код, который мы используем для взвешивания оригинального распределения\n","вероятностей, возвращаемого моделью, и извлечения индекса символа (функция\n","выборки)."]},{"cell_type":"code","metadata":{"id":"JJagpRZ3K_s1","executionInfo":{"status":"ok","timestamp":1636105059673,"user_tz":-420,"elapsed":296,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}}},"source":["# Функция выборки следующего символа с учетом прогнозов модели\n","\n","def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfJpEBMAPaQN"},"source":["Наконец, следующий цикл повторяет обучение и генерирует текст. Для начала\n","сгенерируем текст, использовав разные температуры после каждой эпохи. Это позволит вам увидеть, как меняется генерируемый тест по мере схождения модели\n","и как температура влияет на стратегию выбора."]},{"cell_type":"code","metadata":{"id":"h7v40xVEK_wz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636105327698,"user_tz":-420,"elapsed":66559,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}},"outputId":"e44768c1-2c13-4885-882c-79a05392d5f7"},"source":["# Цикл генерации текста\n","\n","import random\n","import sys\n","temperatures = [0.2, 0.5, 1.0, 1.2]\n","for epoch in range(1, 3):                                                      # Обучение модели в течение 60 эпох\n","    print('epoch', epoch)\n","    model.fit(x, y, batch_size=128, epochs=1)                                   # Выполнение одной итерации обучения\n","\n","start_index = random.randint(0, len(text) - maxlen - 1)                         # Выбор случайного начального текста\n","generated_text = text[start_index: start_index + maxlen]\n","print('--- Generating with seed: \"' + generated_text + '\"')\n","\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1\n","1565/1565 [==============================] - 25s 16ms/step - loss: 1.4321\n","epoch 2\n","1565/1565 [==============================] - 24s 16ms/step - loss: 1.4151\n","--- Generating with seed: \"dividual man himself now goes through too many\n","stages of inn\"\n"]}]},{"cell_type":"code","metadata":{"id":"-Q-d3sXwK_0p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636105492528,"user_tz":-420,"elapsed":77606,"user":{"displayName":"Павел Владимирович Бойков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10883965885344614223"}},"outputId":"004bd46b-4fae-4e1c-aa4f-cc6adc7ea021"},"source":["import random\n","import sys\n","temperatures = [0.2, 0.5, 1.0, 1.2]\n","for temperature in temperatures:\n","    print('------ temperature:', temperature)   \n","    sys.stdout.write(generated_text)    \n","    for i in range(400):                                                        # Генерация 400 символов, начиная с начального текста\n","        sampled = np.zeros((1, maxlen, len(chars)))                             # Прямое кодирование символов, сгенерированных до сих пор\n","        for t, char in enumerate(generated_text):                               \n","            sampled[0, t, char_indices[char]] = 1.    \n","        preds = model.predict(sampled, verbose=0)[0]                            # Выбор следующего символа\n","        next_index = sample(preds, temperature)\n","        next_char = chars[next_index]\n","        generated_text += next_char\n","        generated_text = generated_text[1:]\n","        sys.stdout.write(next_char)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["------ temperature: 0.2\n"," of the contrary of the soul, the thinker of the subject the strong the strong the stands and the strong the promaned the same things the sentiments of the more and the does a things and the fact the stands the precisely the strong the sentiments of the fact the consequently the strong the contrary of the stand the sentiments of the strong the subject the stand in the fact the fact the strong of the consequently in the most consequently the strong the most------ temperature: 0.5\n","he consequently in the most consequently the strong the most sure the principle and will in the fact the objection of the interpretely the play of the general superficial the man from the philosophers or the suddenly the decempt of the senses. the same state the soul and man and stiftion the contrary of the deed and the subject to knowledge, the interes about the superfulness of the privine of the one which the evils and will the the man while the fact the------ temperature: 1.0\n"," one which the evils and will the the man while the fact the 96fully are not\n","more at valition, this relacts _cause, there arises and act ones teme, philosophers of inacause. this finementache through the\n","bedifided more raticing belief\n","instinct of getting in it! there, whill hither protectlyed teantle, oparor, physion the finers through the lower to the worntinment the gratterly been\n","estard the brightes:--there\n","is the readinguted, who have\n","seriousness of th------ temperature: 1.2\n","ghtes:--there\n","is the readinguted, who have\n","seriousness of the pleases and creat lites ofvence\n","aforn thinks ye thour,, for spitus deepe whom to curter are that\n","know threst. \n","\n","244\n","inerful: path, nowe victory of the orde; for, the eading, we had given for exinerful,\n","pimous aroutest that whearionistant litrly\n","univermbe, becirlos\n","of slaraculatism ovour. but\n","mane appartial gremation of charms, twarm of rebliles the\n","ances\n","agains,\n","but usual ajowed wronger of anoth"]}]},{"cell_type":"code","metadata":{"id":"z5-mTxYJK_4Z"},"source":[""],"execution_count":null,"outputs":[]}]}